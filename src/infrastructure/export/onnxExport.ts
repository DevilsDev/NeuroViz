/**
 * ONNX Export Utility
 * 
 * Generates ONNX-compatible model representation from TensorFlow.js models.
 * Since TensorFlow.js doesn't have native ONNX export, this creates a JSON
 * representation that can be converted to ONNX using Python tools.
 */

export interface ONNXModelInfo {
  /** ONNX opset version */
  opsetVersion: number;
  /** Model producer name */
  producerName: string;
  /** Model producer version */
  producerVersion: string;
  /** Input tensor info */
  inputs: ONNXTensorInfo[];
  /** Output tensor info */
  outputs: ONNXTensorInfo[];
  /** Network layers/nodes */
  nodes: ONNXNode[];
  /** Initializers (weights) */
  initializers: ONNXInitializer[];
}

export interface ONNXTensorInfo {
  name: string;
  shape: number[];
  dataType: 'float32' | 'int64';
}

export interface ONNXNode {
  name: string;
  opType: string;
  inputs: string[];
  outputs: string[];
  attributes?: Record<string, unknown>;
}

export interface ONNXInitializer {
  name: string;
  shape: number[];
  data: number[];
}

/**
 * Generates ONNX model info from layer configuration and weights.
 * 
 * @param layers - Array of layer sizes [input, hidden1, ..., output]
 * @param activations - Activation function per layer
 * @param weights - Weight matrices [layer][from][to]
 * @param biases - Bias vectors per layer
 * @returns ONNX model representation
 */
export function generateONNXModel(
  layers: number[],
  activations: string[],
  weights: number[][][],
  biases: number[][]
): ONNXModelInfo {
  const nodes: ONNXNode[] = [];
  const initializers: ONNXInitializer[] = [];
  
  let currentInput = 'input';
  
  // Generate nodes for each layer
  for (let i = 0; i < layers.length - 1; i++) {
    const inputSize = layers[i] ?? 2;
    const outputSize = layers[i + 1] ?? 1;
    const layerWeights = weights[i] ?? [];
    const layerBiases = biases[i] ?? [];
    const activation = activations[i + 1] ?? 'relu';
    
    const weightName = `layer${i}_weight`;
    const biasName = `layer${i}_bias`;
    const matmulOutput = `layer${i}_matmul`;
    const addOutput = `layer${i}_add`;
    const activationOutput = i === layers.length - 2 ? 'output' : `layer${i}_activation`;
    
    // Add weight initializer (transposed for ONNX format)
    const flatWeights: number[] = [];
    for (let j = 0; j < outputSize; j++) {
      for (let k = 0; k < inputSize; k++) {
        flatWeights.push(layerWeights[k]?.[j] ?? 0);
      }
    }
    
    initializers.push({
      name: weightName,
      shape: [outputSize, inputSize],
      data: flatWeights,
    });
    
    // Add bias initializer
    initializers.push({
      name: biasName,
      shape: [outputSize],
      data: layerBiases.length > 0 ? layerBiases : Array(outputSize).fill(0),
    });
    
    // MatMul node (Gemm in ONNX)
    nodes.push({
      name: `${matmulOutput}_node`,
      opType: 'Gemm',
      inputs: [currentInput, weightName, biasName],
      outputs: [addOutput],
      attributes: {
        alpha: 1.0,
        beta: 1.0,
        transB: 1,
      },
    });
    
    // Activation node
    const onnxActivation = mapActivationToONNX(activation);
    if (onnxActivation !== 'Identity') {
      nodes.push({
        name: `${activationOutput}_node`,
        opType: onnxActivation,
        inputs: [addOutput],
        outputs: [activationOutput],
      });
      currentInput = activationOutput;
    } else {
      currentInput = addOutput;
    }
  }
  
  return {
    opsetVersion: 13,
    producerName: 'NeuroViz',
    producerVersion: '1.0.0',
    inputs: [{
      name: 'input',
      shape: [-1, layers[0] ?? 2], // -1 for batch dimension
      dataType: 'float32',
    }],
    outputs: [{
      name: 'output',
      shape: [-1, layers[layers.length - 1] ?? 1],
      dataType: 'float32',
    }],
    nodes,
    initializers,
  };
}

/**
 * Maps TensorFlow.js activation names to ONNX operator types.
 */
function mapActivationToONNX(activation: string): string {
  switch (activation.toLowerCase()) {
    case 'relu': return 'Relu';
    case 'sigmoid': return 'Sigmoid';
    case 'tanh': return 'Tanh';
    case 'elu': return 'Elu';
    case 'softmax': return 'Softmax';
    case 'linear':
    case 'none':
    default: return 'Identity';
  }
}

/**
 * Generates a Python script that creates an ONNX model from the exported data.
 * 
 * @param modelInfo - ONNX model information
 * @returns Python script as string
 */
export function generateONNXPythonScript(modelInfo: ONNXModelInfo): string {
  const inputShape = modelInfo.inputs[0]?.shape ?? [-1, 2];
  const outputShape = modelInfo.outputs[0]?.shape ?? [-1, 1];
  
  return `"""
ONNX Model Generator
Generated by NeuroViz - https://github.com/your-repo/neuroviz

This script creates an ONNX model from the exported NeuroViz configuration.
Requires: pip install onnx numpy
"""

import numpy as np
import onnx
from onnx import helper, TensorProto

# Model metadata
opset_version = ${modelInfo.opsetVersion}
producer_name = "${modelInfo.producerName}"
producer_version = "${modelInfo.producerVersion}"

# Create initializers (weights and biases)
initializers = []
${modelInfo.initializers.map(init => `
# ${init.name}
${init.name}_data = np.array(${JSON.stringify(init.data)}, dtype=np.float32).reshape(${JSON.stringify(init.shape)})
initializers.append(helper.make_tensor(
    name="${init.name}",
    data_type=TensorProto.FLOAT,
    dims=${JSON.stringify(init.shape)},
    vals=${init.name}_data.flatten().tolist()
))
`).join('')}

# Create nodes
nodes = []
${modelInfo.nodes.map(node => `
nodes.append(helper.make_node(
    "${node.opType}",
    inputs=${JSON.stringify(node.inputs)},
    outputs=${JSON.stringify(node.outputs)},
    name="${node.name}"${node.attributes ? `,
    **${JSON.stringify(node.attributes)}` : ''}
))
`).join('')}

# Create input/output
input_tensor = helper.make_tensor_value_info("input", TensorProto.FLOAT, ${JSON.stringify(inputShape)})
output_tensor = helper.make_tensor_value_info("output", TensorProto.FLOAT, ${JSON.stringify(outputShape)})

# Create graph
graph = helper.make_graph(
    nodes,
    "neuroviz_model",
    [input_tensor],
    [output_tensor],
    initializers
)

# Create model
model = helper.make_model(graph, opset_imports=[helper.make_opsetid("", opset_version)])
model.producer_name = producer_name
model.producer_version = producer_version

# Validate and save
onnx.checker.check_model(model)
onnx.save(model, "neuroviz_model.onnx")
print("Model saved to neuroviz_model.onnx")

# Test inference (optional)
try:
    import onnxruntime as ort
    session = ort.InferenceSession("neuroviz_model.onnx")
    test_input = np.random.randn(1, ${inputShape[1] ?? 2}).astype(np.float32)
    result = session.run(None, {"input": test_input})
    print(f"Test inference successful. Output shape: {result[0].shape}")
except ImportError:
    print("Install onnxruntime to test inference: pip install onnxruntime")
`;
}

/**
 * Exports model info as downloadable JSON.
 */
export function downloadONNXJson(modelInfo: ONNXModelInfo, filename = 'neuroviz_model_onnx.json'): void {
  const json = JSON.stringify(modelInfo, null, 2);
  const blob = new Blob([json], { type: 'application/json' });
  const url = URL.createObjectURL(blob);
  
  const a = document.createElement('a');
  a.href = url;
  a.download = filename;
  a.click();
  
  URL.revokeObjectURL(url);
}

/**
 * Exports Python ONNX generator script.
 */
export function downloadONNXPythonScript(modelInfo: ONNXModelInfo, filename = 'generate_onnx.py'): void {
  const script = generateONNXPythonScript(modelInfo);
  const blob = new Blob([script], { type: 'text/x-python' });
  const url = URL.createObjectURL(blob);
  
  const a = document.createElement('a');
  a.href = url;
  a.download = filename;
  a.click();
  
  URL.revokeObjectURL(url);
}
