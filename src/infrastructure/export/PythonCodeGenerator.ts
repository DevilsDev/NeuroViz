import type { Hyperparameters, LRScheduleConfig } from '../../core/domain';

/**
 * Generates equivalent Keras/TensorFlow Python code for the current model configuration.
 */
export function generatePythonCode(
  hyperparams: Hyperparameters,
  lrSchedule?: LRScheduleConfig,
  datasetInfo?: { samples: number; noise: number; datasetType: string }
): string {
  const lines: string[] = [];

  // Imports
  lines.push('"""');
  lines.push('Neural Network Configuration - Generated by NeuroViz');
  lines.push(`Generated: ${new Date().toISOString()}`);
  lines.push('"""');
  lines.push('');
  lines.push('import numpy as np');
  lines.push('import tensorflow as tf');
  lines.push('from tensorflow import keras');
  lines.push('from tensorflow.keras import layers, regularizers, optimizers');
  lines.push('from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler');
  lines.push('from sklearn.datasets import make_circles, make_moons, make_blobs, make_classification');
  lines.push('from sklearn.model_selection import train_test_split');
  lines.push('from sklearn.preprocessing import StandardScaler');
  lines.push('');

  // Dataset generation
  if (datasetInfo) {
    lines.push('# Generate dataset');
    lines.push(`n_samples = ${datasetInfo.samples}`);
    lines.push(`noise = ${datasetInfo.noise}`);
    lines.push('');

    switch (datasetInfo.datasetType) {
      case 'circle':
        lines.push('X, y = make_circles(n_samples=n_samples, noise=noise, factor=0.5)');
        break;
      case 'xor':
        lines.push('X, y = make_classification(n_samples=n_samples, n_features=2, n_redundant=0,');
        lines.push('                           n_informative=2, n_clusters_per_class=1, flip_y=noise)');
        break;
      case 'spiral':
        lines.push('# Spiral dataset');
        lines.push('theta = np.sqrt(np.random.rand(n_samples // 2)) * 2 * np.pi');
        lines.push('r_a = 2 * theta + np.pi');
        lines.push('r_b = -2 * theta - np.pi');
        lines.push('X = np.vstack([');
        lines.push('    np.column_stack([r_a * np.cos(theta), r_a * np.sin(theta)]),');
        lines.push('    np.column_stack([r_b * np.cos(theta), r_b * np.sin(theta)])');
        lines.push(']) + np.random.randn(n_samples, 2) * noise');
        lines.push('y = np.hstack([np.zeros(n_samples // 2), np.ones(n_samples // 2)])');
        break;
      case 'moons':
        lines.push('X, y = make_moons(n_samples=n_samples, noise=noise)');
        break;
      case 'clusters':
        lines.push(`X, y = make_blobs(n_samples=n_samples, centers=${hyperparams.numClasses}, cluster_std=noise * 2)`);
        break;
      default:
        lines.push('X, y = make_circles(n_samples=n_samples, noise=noise, factor=0.5)');
    }

    lines.push('');
    lines.push('# Normalize features');
    lines.push('scaler = StandardScaler()');
    lines.push('X = scaler.fit_transform(X)');
    lines.push('');
    lines.push('# Train/test split');
    lines.push('X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)');
    lines.push('');
  }

  // Model definition
  lines.push('# Build model');
  lines.push('model = keras.Sequential([');

  // Input layer
  lines.push('    layers.Input(shape=(2,)),');

  // Hidden layers
  const layers_config = hyperparams.layers;
  const defaultActivation = hyperparams.activation ?? 'relu';
  const layerActivations = hyperparams.layerActivations ?? [];

  for (let i = 0; i < layers_config.length; i++) {
    const units = layers_config[i];
    const activation = layerActivations[i] ?? defaultActivation;
    
    // Regularization
    const regParts: string[] = [];
    if (hyperparams.l1Regularization && hyperparams.l1Regularization > 0) {
      regParts.push(`l1=${hyperparams.l1Regularization}`);
    }
    if (hyperparams.l2Regularization && hyperparams.l2Regularization > 0) {
      regParts.push(`l2=${hyperparams.l2Regularization}`);
    }
    const regStr = regParts.length > 0 
      ? `, kernel_regularizer=regularizers.L1L2(${regParts.join(', ')})` 
      : '';

    lines.push(`    layers.Dense(${units}, activation='${activation}'${regStr}),`);

    // Batch normalization
    if (hyperparams.batchNorm) {
      lines.push('    layers.BatchNormalization(),');
    }

    // Dropout
    if (hyperparams.dropoutRate && hyperparams.dropoutRate > 0) {
      lines.push(`    layers.Dropout(${hyperparams.dropoutRate}),`);
    }
  }

  // Output layer
  const numClasses = hyperparams.numClasses ?? 2;
  if (numClasses === 2) {
    lines.push("    layers.Dense(1, activation='sigmoid')");
  } else {
    lines.push(`    layers.Dense(${numClasses}, activation='softmax')`);
  }

  lines.push('])');
  lines.push('');

  // Optimizer
  lines.push('# Configure optimizer');
  const lr = hyperparams.learningRate;
  
  switch (hyperparams.optimizer) {
    case 'sgd': {
      const momentum = hyperparams.momentum ?? 0.9;
      lines.push(`optimizer = optimizers.SGD(learning_rate=${lr}, momentum=${momentum})`);
      break;
    }
    case 'adam':
      lines.push(`optimizer = optimizers.Adam(learning_rate=${lr})`);
      break;
    case 'rmsprop':
      lines.push(`optimizer = optimizers.RMSprop(learning_rate=${lr})`);
      break;
    case 'adagrad':
      lines.push(`optimizer = optimizers.Adagrad(learning_rate=${lr})`);
      break;
    default:
      lines.push(`optimizer = optimizers.Adam(learning_rate=${lr})`);
  }
  lines.push('');

  // Compile
  lines.push('# Compile model');
  if (numClasses === 2) {
    lines.push("model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])");
  } else {
    lines.push("model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])");
  }
  lines.push('');

  // Learning rate schedule
  if (lrSchedule && lrSchedule.type !== 'none') {
    lines.push('# Learning rate schedule');
    
    switch (lrSchedule.type) {
      case 'exponential':
        lines.push(`def lr_schedule(epoch):
    initial_lr = ${lr}
    decay_rate = 0.95
    return initial_lr * (decay_rate ** epoch)`);
        break;
      case 'step':
        lines.push(`def lr_schedule(epoch):
    initial_lr = ${lr}
    drop_rate = 0.5
    epochs_drop = 50
    return initial_lr * (drop_rate ** (epoch // epochs_drop))`);
        break;
      case 'cosine':
        lines.push(`def lr_schedule(epoch, total_epochs=500):
    initial_lr = ${lr}
    return initial_lr * 0.5 * (1 + np.cos(np.pi * epoch / total_epochs))`);
        break;
      case 'cyclic_triangular':
        lines.push(`def lr_schedule(epoch):
    initial_lr = ${lr}
    min_lr = ${lrSchedule.minLR ?? 0.001}
    cycle_length = ${lrSchedule.cycleLength ?? 20}
    cycle_position = epoch % cycle_length
    if cycle_position < cycle_length / 2:
        return min_lr + (initial_lr - min_lr) * (2 * cycle_position / cycle_length)
    else:
        return initial_lr - (initial_lr - min_lr) * (2 * (cycle_position - cycle_length / 2) / cycle_length)`);
        break;
      default:
        lines.push(`def lr_schedule(epoch):
    return ${lr}`);
    }
    
    lines.push('');
    lines.push('lr_callback = LearningRateScheduler(lr_schedule)');
    lines.push('');
  }

  // Callbacks
  lines.push('# Callbacks');
  lines.push('callbacks = [');
  lines.push("    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),");
  if (lrSchedule && lrSchedule.type !== 'none') {
    lines.push('    lr_callback,');
  }
  lines.push(']');
  lines.push('');

  // Training
  lines.push('# Train model');
  lines.push('history = model.fit(');
  lines.push('    X_train, y_train,');
  lines.push('    validation_data=(X_test, y_test),');
  lines.push('    epochs=500,');
  lines.push('    batch_size=32,');
  lines.push('    callbacks=callbacks,');
  lines.push('    verbose=1');
  lines.push(')');
  lines.push('');

  // Evaluation
  lines.push('# Evaluate');
  lines.push('test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)');
  lines.push("print(f'Test accuracy: {test_acc:.4f}')");
  lines.push('');

  // Summary
  lines.push('# Model summary');
  lines.push('model.summary()');

  return lines.join('\n');
}
